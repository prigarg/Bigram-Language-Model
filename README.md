# Bigram-Language-Model
A Bigram Language Model is trained for the training corpus with no-smoothing and add-one smoothing. For testing purpose, bigram counts, bigram probabilities for the test sentence along with the probability of test sentence under the trained model is printed to a text file. A detailed working explanation of code is documented in the program.
